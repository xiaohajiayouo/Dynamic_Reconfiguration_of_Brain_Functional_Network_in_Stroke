{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from nilearn import datasets, plotting, input_data, signal  # for fetching atlas\n",
    "\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from nistats.reporting import plot_design_matrix\n",
    "from nistats.design_matrix import make_first_level_design_matrix\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "\n",
    "from fctools import denoise, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import numpy as np\n",
    "import os \n",
    "from glob import *\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# top_dir = 'H:\\\\Jupyter\\\\Stroke15\\\\Multilayer_stroke15\\\\Results\\\\01-extracted_timeseries'\n",
    "# out_dir = 'H:\\\\Matlab\\\\Work\\\\Stroke15\\\\Mutilayer\\\\ROI_denoising'\n",
    "\n",
    "# n_sub = 30\n",
    "# parcellations = np.asarray([['power', 'Power', 264], \n",
    "#                             ['schaefer', 'Schaefer', 300]])\n",
    "\n",
    "# from sklearn.covariance import EmpiricalCovariance\n",
    "# for p in parcellations:\n",
    "#     print(p)\n",
    "#     print(f'{p[0]} parcellation static FC')\n",
    "#     path = f'{top_dir}\\\\timeseries_{p[0]}_no_smooth_denoised_.npy'\n",
    "#     parced_data = np.load(path)\n",
    "#     print(parced_data.shape)\n",
    "#     for sub,timeseries in enumerate(parced_data):\n",
    "#         print(sub,timeseries.shape)\n",
    "#         if sub+1 <10:\n",
    "#             np.savetxt(out_dir+'\\\\'+ p[1]+'\\\\Sub_00'+ str(sub+1)+'.txt', timeseries)\n",
    "#         else:\n",
    "#             np.savetxt(out_dir+'\\\\'+ p[1]+'\\\\Sub_0'+ str(sub+1)+'.txt', timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['power' 'Power' '264']\n",
      "power parcellation static FC\n",
      "Sub_1 finished\n",
      "Sub_2 finished\n",
      "Sub_3 finished\n",
      "Sub_4 finished\n",
      "Sub_5 finished\n",
      "Sub_6 finished\n",
      "Sub_7 finished\n",
      "Sub_8 finished\n",
      "Sub_9 finished\n",
      "Sub_10 finished\n",
      "Sub_11 finished\n",
      "Sub_12 finished\n",
      "Sub_13 finished\n",
      "Sub_14 finished\n",
      "Sub_15 finished\n",
      "Sub_16 finished\n",
      "Sub_17 finished\n",
      "Sub_18 finished\n",
      "Sub_19 finished\n",
      "Sub_20 finished\n",
      "Sub_21 finished\n",
      "Sub_22 finished\n",
      "Sub_23 finished\n",
      "Sub_24 finished\n",
      "Sub_25 finished\n",
      "Sub_26 finished\n",
      "Sub_27 finished\n",
      "Sub_28 finished\n",
      "Sub_29 finished\n",
      "Sub_30 finished\n",
      "(30, 264, 264)\n",
      "['schaefer' 'Schaefer' '300']\n",
      "schaefer parcellation static FC\n",
      "Sub_1 finished\n",
      "Sub_2 finished\n",
      "Sub_3 finished\n",
      "Sub_4 finished\n",
      "Sub_5 finished\n",
      "Sub_6 finished\n",
      "Sub_7 finished\n",
      "Sub_8 finished\n",
      "Sub_9 finished\n",
      "Sub_10 finished\n",
      "Sub_11 finished\n",
      "Sub_12 finished\n",
      "Sub_13 finished\n",
      "Sub_14 finished\n",
      "Sub_15 finished\n",
      "Sub_16 finished\n",
      "Sub_17 finished\n",
      "Sub_18 finished\n",
      "Sub_19 finished\n",
      "Sub_20 finished\n",
      "Sub_21 finished\n",
      "Sub_22 finished\n",
      "Sub_23 finished\n",
      "Sub_24 finished\n",
      "Sub_25 finished\n",
      "Sub_26 finished\n",
      "Sub_27 finished\n",
      "Sub_28 finished\n",
      "Sub_29 finished\n",
      "Sub_30 finished\n",
      "(30, 300, 300)\n"
     ]
    }
   ],
   "source": [
    "top_dir = 'H:\\\\Jupyter\\\\Stroke15\\\\Multilayer_stroke15\\\\Results\\\\01-extracted_timeseries'\n",
    "out_dir = 'H:\\\\Matlab\\\\Work\\\\Stroke15\\\\Mutilayer\\\\Results\\\\No_smooth_fc'\n",
    "out2_dir = 'H:\\\\Jupyter\\\\Stroke15\\\\Multilayer_stroke15\\\\Results\\\\01-extracted_timeseries\\\\'\n",
    "n_sub = 30\n",
    "parcellations = np.asarray([['power', 'Power', 264], \n",
    "                            ['schaefer', 'Schaefer', 300]])\n",
    "\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "for p in parcellations:\n",
    "    print(p)\n",
    "    print(f'{p[0]} parcellation static FC')\n",
    "    path = f'{top_dir}\\\\timeseries_{p[0]}_no_smooth_denoised_.npy'\n",
    "    parced_data = np.load(path) \n",
    "    correlation_matrices = np.zeros((n_sub,int(p[2]),int(p[2])))\n",
    "    for sub, p_data in enumerate(parced_data):\n",
    "    \n",
    "        correlation_measure = ConnectivityMeasure(cov_estimator=EmpiricalCovariance(store_precision=True, assume_centered=False), kind = 'correlation', discard_diagonal=True)\n",
    "\n",
    "        fc = correlation_measure.fit_transform([p_data])[0]\n",
    "#         print(fc.shape)\n",
    "        np.fill_diagonal(fc, 0)\n",
    "        z_fc = np.arctanh(fc)\n",
    "        correlation_matrices[sub, :, :] =  z_fc\n",
    "        \n",
    "        if sub+1 <10:\n",
    "            np.savetxt(out_dir+'\\\\'+ p[1]+'\\\\Sub_00'+ str(sub+1)+'.txt', z_fc)\n",
    "        else:\n",
    "            np.savetxt(out_dir+'\\\\'+ p[1]+'\\\\Sub_0'+ str(sub+1)+'.txt', z_fc)\n",
    "        print(f\"Sub_{sub+1} finished\")\n",
    "    print(correlation_matrices.shape)\n",
    "    np.save(f'{out2_dir}{p[0]}_static_correlation_matrices_nosmooth.npy', correlation_matrices) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-78a2859c0622>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mout_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\\\'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\\\Sub_00'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_fc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'out_dir' is not defined"
     ]
    }
   ],
   "source": [
    "out_dir+'\\\\'+ p[1]+'\\\\Sub_00'+ str(sub+1)+'.txt', z_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'{top_dir}\\\\{p[0]}_static_correlation_matrices_nosmooth.npy'\n",
    "parced_data = np.load(path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 300, 300)\n",
      "[[ 0.          0.49727395  0.43026518 ... -0.06638943 -0.06402886\n",
      "   0.25014109]\n",
      " [ 0.49727395  0.          0.01235736 ...  0.51894721  0.52529467\n",
      "   0.78027533]\n",
      " [ 0.43026518  0.01235736  0.         ... -0.04144825 -0.11661638\n",
      "  -0.0484317 ]\n",
      " ...\n",
      " [-0.06638943  0.51894721 -0.04144825 ...  0.          1.13602396\n",
      "   0.75730278]\n",
      " [-0.06402886  0.52529467 -0.11661638 ...  1.13602396  0.\n",
      "   0.84414042]\n",
      " [ 0.25014109  0.78027533 -0.0484317  ...  0.75730278  0.84414042\n",
      "   0.        ]]\n",
      "[[ 0.          1.13350458 -0.00114769 ...  0.82098958  0.33641842\n",
      "   0.65698653]\n",
      " [ 1.13350458  0.         -0.08552946 ...  0.88680444  0.52625576\n",
      "   0.82775575]\n",
      " [-0.00114769 -0.08552946  0.         ... -0.22527633 -0.00141143\n",
      "  -0.1404437 ]\n",
      " ...\n",
      " [ 0.82098958  0.88680444 -0.22527633 ...  0.          0.5789799\n",
      "   0.95545499]\n",
      " [ 0.33641842  0.52625576 -0.00141143 ...  0.5789799   0.\n",
      "   0.73447112]\n",
      " [ 0.65698653  0.82775575 -0.1404437  ...  0.95545499  0.73447112\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(parced_data.shape)\n",
    "print(parced_data[1])\n",
    "print(parced_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dir = 'H:\\\\Jupyter\\\\Stroke15\\\\Multilayer_stroke15\\\\Results\\\\01-extracted_timeseries'\n",
    "out_dir = 'H:\\Matlab\\Work\\Stroke15\\Mutilayer\\Results\\FC'\n",
    "out2_dir = 'H:\\\\Jupyter\\\\Stroke15\\\\Multilayer_stroke15\\\\Results\\\\01-extracted_timeseries\\\\'\n",
    "n_sub = 30\n",
    "parcellations = np.asarray([['network32', 'Network32', 264]\n",
    "                            ,['power', 'Power', 264], \n",
    "                            ['schaefer', 'Schaefer', 300]])\n",
    "\n",
    "power_denoised_npy= np.load(f'{out2_dir}timeseries_{parcellations[1][0]}_denoised_.npy')\n",
    "power_fc_npy= np.load(f'{out2_dir}{parcellations[1][0]}_static_correlation_matrices.npy') \n",
    "\n",
    "\n",
    "schaefer_denoised_npy= np.load(f'{out2_dir}timeseries_{parcellations[2][0]}_denoised_.npy')\n",
    "schaefer_fc_npy= np.load(f'{out2_dir}{parcellations[2][0]}_static_correlation_matrices.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_path = 'H:\\Matlab\\Work\\Stroke15\\Mutilayer\\ROI_denoising\\\\'\n",
    "network32_denosied_path =  denoised_path+parcellations[0][1]\n",
    "newtwork32_correlation_matrices =np.zeros((30,32,32))\n",
    "for sub in range(30):\n",
    "    if sub+1 <10:\n",
    "        denoised_data  =np.loadtxt(network32_denosied_path+'//'+ '//Sub_00'+ str(sub+1)+'.txt')\n",
    "    else:\n",
    "        denoised_data = np.loadtxt(network32_denosied_path+'//'+ '//Sub_0'+ str(sub+1)+'.txt')\n",
    "    correlation_measure = ConnectivityMeasure(cov_estimator=EmpiricalCovariance(store_precision=True, assume_centered=False), kind = 'correlation', discard_diagonal=True)\n",
    "    \n",
    "    fc = correlation_measure.fit_transform([denoised_data])[0]\n",
    "    np.fill_diagonal(fc, 0)\n",
    "    z_fc = np.arctanh(fc)\n",
    "    newtwork32_correlation_matrices[sub, :, :] =  z_fc\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
