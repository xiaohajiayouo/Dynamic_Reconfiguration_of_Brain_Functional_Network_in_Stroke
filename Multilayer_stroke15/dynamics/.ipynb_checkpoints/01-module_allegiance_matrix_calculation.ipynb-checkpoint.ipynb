{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from nilearn import plotting \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "from fctools import networks, figures\n",
    "\n",
    "#---- matplotlib settings\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "import scipy.io as scio\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01- chose the path storing the multilayer results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_path = 'H:\\Matlab\\Work\\Stroke15\\Mutilayer\\DFC'\n",
    "parcellations = np.asarray([['network', 'Network32', 32],\n",
    "                            ['power', 'Power', 264], \n",
    "                            ['schaefer', 'Schaefer', 300]])\n",
    "data_path = top_path+'\\\\'+parcellations[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02- load the multilayer results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 100, 32, 179)\n"
     ]
    }
   ],
   "source": [
    "modules_omega = scio.loadmat(os.path.join(data_path,'Modules_rep.mat'))\n",
    "modularity_q_omega = scio.loadmat(os.path.join(data_path,'Modularity_rep.mat'))\n",
    "\n",
    "modules_rep = modules_omega['modules_rep']\n",
    "modularity_q_means = modularity_q_omega['modularity_rep']\n",
    "modules_rep.shape # (30, 100, 32, 179)\n",
    "modularity_q_means.shape # (30, 100)\n",
    "\n",
    "module_assignment = modules_rep\n",
    "print(module_assignment.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03- computering the allegiance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 100 32\n",
      "Subject 1\n",
      "Subject 2\n",
      "Subject 3\n",
      "Subject 4\n",
      "Subject 5\n",
      "Subject 6\n",
      "Subject 7\n",
      "Subject 8\n",
      "Subject 9\n",
      "Subject 10\n",
      "Subject 11\n",
      "Subject 12\n",
      "Subject 13\n",
      "Subject 14\n",
      "Subject 15\n",
      "Subject 16\n",
      "Subject 17\n",
      "Subject 18\n",
      "Subject 19\n",
      "Subject 20\n",
      "Subject 21\n",
      "Subject 22\n",
      "Subject 23\n",
      "Subject 24\n",
      "Subject 25\n",
      "Subject 26\n",
      "Subject 27\n",
      "Subject 28\n",
      "Subject 29\n",
      "Subject 30\n"
     ]
    }
   ],
   "source": [
    "n_sub = module_assignment.shape[0]\n",
    "n_opt = module_assignment.shape[1]\n",
    "n_nod = module_assignment.shape[2]\n",
    "print(n_sub,n_opt,n_nod)\n",
    "\n",
    "P = np.zeros((n_sub, n_nod, n_nod))\n",
    "\n",
    "for i in range(n_sub):\n",
    "    print(f'Subject {i+1}')\n",
    "    P[i,:,:] = networks.allegiance_matrix_opti(module_assignment[i,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_networks_mean(matrix, labels, n_iter):\n",
    "    '''Normalizing recruitment and integration values using permutation approach\n",
    "    Null module allegiance matrices were created by randomly permuting the correspondence \n",
    "    between regions of interest (ROIs) and large-scale systems.\n",
    "    We then calculated the functional cartography measures for all permuted matrices.  \n",
    "    To obtain normalized values of recruitment and integration, \n",
    "    we divided them by the mean of the corresponding null distribution.\n",
    "    This procedure yielded null distributions of recruitment \n",
    "    and integration coefficients resulting solely from the size of each system.\n",
    "    \n",
    "    Args:\n",
    "        matrix: (N x N)\n",
    "        labels: (N, )\n",
    "        n_iter: int\n",
    "    '''\n",
    "    n_networks = len(np.unique(labels))\n",
    "\n",
    "    def calculate_networks_mean(matrix, labels, n_networks):\n",
    "        '''... '''\n",
    "        nam = np.zeros((n_networks, n_networks))\n",
    "\n",
    "        for i in range(n_networks):\n",
    "            for j in range(n_networks):\n",
    "                nam[i, j] = np.mean(matrix[np.nonzero(labels == i+1)][:, np.nonzero(labels == j+1)])\n",
    "        return nam\n",
    "\n",
    "    nam = calculate_networks_mean(matrix, labels, n_networks)\n",
    "    nam_null = np.zeros((n_networks, n_networks))\n",
    "    labels_null = labels.copy()\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        np.random.shuffle(labels_null)\n",
    "        nam_null += calculate_networks_mean(matrix, labels_null, n_networks)\n",
    "\n",
    "    nam_null /= n_iter    \n",
    "\n",
    "    return np.divide(nam, nam_null)\n",
    "\n",
    "# Calculate mean normalized allegiance\n",
    "# eval(f'{parcellation}_labels')\n",
    "parcellation = 'network32'\n",
    "\n",
    "out_dir = 'H:\\\\Jupyter\\\\Stroke15\\\\Multilayer_stroke15\\\\Results\\\\02-multilayer'\n",
    "\n",
    "n_net = len(np.unique(roi_networks))\n",
    "norm_mean_allegiance = np.zeros((n_sub,n_net, n_net))\n",
    "\n",
    "for i in range(n_sub):\n",
    "    print(f'Subject {i+1}')\n",
    "    norm_mean_allegiance[i] = normalize_networks_mean(P[i], roi_lab_inx, 1000)\n",
    "    \n",
    "    \n",
    "np.save(f'{out_dir}\\\\{parcellation}\\\\whole-brain_network_normalized_mean_allegiance_corrected.npy', norm_mean_allegiance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H:\\\\Jupyter\\\\Stroke15\\\\Multilayer_stroke15\\\\Results\\\\02-multilayer\\\\network32\\\\whole-brain_network_normalized_mean_allegiance_corrected.npy'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir = 'H:\\\\Jupyter\\\\Stroke15\\\\Multilayer_stroke15\\\\Results\\\\02-multilayer'\n",
    "parcellation = 'network32'\n",
    "f'{out_dir}\\\\{parcellation}\\\\whole-brain_network_normalized_mean_allegiance_corrected.npy'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
